\newpage
\section{Discussion}
\par Overall, MIDSX shows relative agreement with the PENELOPE, EGSnrc, Geant4, and MCNP results provided by TG-195 for the three examined cases. For the HVL layer simulation described by Case 1, statistical agreement is seen with all code systems except for PENELOPE for the HVL and QVL 100 keV simulation. In addition, for the 30 keV simulation, statistical agreement is seen with PENELOPE, Geant4, and MCNP for HVL, along with PENELOPE and MCNP for QVL. Note that while no statistical agreement is observed for the other energies/thicknesses, all MIDSX results are within 0.32\% of the mean of the reference code systems.

\par For Case 2, agreement is rather varied. For the full-field ROI measurements not shown in this paper due page constraints, very little statistical agreement is seen between the code systems; however, a $<3$\% mean percent error (MPE) is seen for MIDSX's results to each ROI simulation. Furthermore, for the pencil-beam ROI measurements shown in Fig \ref{fig:ROIPGraph}, statistical agreement is not readily observed, but a $<2.1$\% MPE is observed for each ROI simulation expect for the case of a single incoherent scatter. In this particular case, MIDSX's results for ROI 4 and 5 are significantly lower, with the MPE reaching 10\% for ROI 5. This discrepancy is likely a result of an error in the rejection sampling algorithm employed by MIDSX. While this algorithm shows agreement for the full-field ROI 5, the geometry of the ROI, combined with the pencil beam, results in only narrow angle scatters hitting the ROI. Since the scattering angle distribution of incoherent scattering at the medical imaging energy range contains a vertical asymptote approaching 0 at $\theta = 0^\circ$, there is likely some form of numerical instability presenting itself in the algorithm that needs to be analyzed.

\par In the full-field tissue deposition measurements depicted in Fig \ref{fig:BDGraph}, we do not observe statistical agreement. However, for the $0^\circ$ case, the disagreement between code systems is minimal with an MPE of less than 0.1\% for MIDSX. Conversely, for the MIDSX results at $15^\circ$, the MPE reaches approximately 0.5\%. Despite extensive investigations into this pronounced discrepancy, a solution remains elusive.

\par For Case 5, almost all of MIDSX's results are marginally lower than the mean of the reference code systems, with MPE's ranging from 1.1\% to 6.3\%. This pattern is disrupted by the thyroid, which is larger than the mean by 2.9\%. In order to quantify the cumulative error, the root mean square percent error (RMSPE) was calculated using each organ result, which resulted in the RMSPE for MIDSX being 5\%. In addition, with all other code systems typically having an MPE less than 1\%, except for MCNP which reaches an MPE of 2.2\% for the breast, there appears to a systematic error with the MIDSX code system with regard to the CT simulation. One common error reported by TG-195 is the incorrect orientation of the voxelized phantom in the computational domain. On top of checking the scenes geometry and the .comp file, the orientation was verified by taking the RMSPE of the MIDSX data with respect to the results of each simulated angle reported by TG-195. As expected, the RMSPE with respect the $0^\circ$ was the minimum, further solidifying the belief that the phantom's orientation during the CT simulation is accurate.

\par However, despite the orientation being verified, the consistent deviation of MIDSX energy deposition results for both Case 2 and 5 raises concerns. This suggests that there may be other underlying issues or intricacies in the MIDSX system that need further investigation. Potential factors could include the software's handling of certain physics processes, voxel resolution, or computational approximations. It's imperative for future research to delve deeper into these aspects to pinpoint and rectify the source of the systematic errors observed in the MIDSX results.

